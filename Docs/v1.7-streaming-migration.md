# v1.7 - Streaming Progress & OpenAI Responses API Migration

## Summary
Major refactor implementing real-time streaming feedback for schema generation and migrating from OpenAI's legacy Chat Completions API to the recommended Responses API.

## Key Features

### 1. Real-Time Streaming Progress (v1.7.0)
- Implemented Server-Sent Events (SSE) for real-time progress updates
- Users see live feedback during schema generation
- Button text updates with character counts and elapsed time
- Keepalive events prevent network timeouts

### 2. OpenAI Responses API Migration (v1.7.1-1.7.8)
- Migrated from `/v1/chat/completions` to `/v1/responses`
- Updated request format: `messages` â†’ `input`
- Updated parameters: `max_completion_tokens` â†’ `max_output_tokens`
- Proper support for `reasoning.effort` and `text.verbosity` parameters

### 3. GPT-5 Model Optimization
- Set `reasoning.effort: minimal` for GPT-5-nano
- Set `text.verbosity: low` for concise responses
- Reduced generation time from ~190 seconds to 10-20 seconds

## Critical Bugs Fixed

### Bug #1: Wrong Default Model (v1.7.3)
**Problem:** Streaming handler defaulted to `gpt-4o-mini` instead of `gpt-5-nano`
**Impact:** Reasoning optimizations were never applied, causing 5-minute waits
**Fix:** Changed default to match provider's `DEFAULT_MODEL` constant

### Bug #2: Connection Termination (v1.7.7)
**Problem:** `fastcgi_finish_request()` was closing client connection prematurely
**Impact:** Pass 2 ran invisibly on server, no UI feedback
**Fix:** Replaced with proper `ob_flush()` + `flush()`

### Bug #3: Private Method Visibility (v1.7.8)
**Problem:** `build_messages()` was private in provider classes
**Impact:** Fatal error when streaming handler tried to call it for Pass 2
**Fix:** Changed method visibility to `public`

### Bug #4: Streaming Format Mismatch (v1.7.1)
**Problem:** Looking for wrong streaming format (`choices[0].delta.content` vs `response.output_text.delta`)
**Impact:** No content received during streaming
**Fix:** Updated to handle Responses API event format

## Files Modified

### Core Changes
- `includes/class-streaming-handler.php` - New SSE streaming endpoint
- `assets/js/metabox.js` - Frontend EventSource handling
- `providers/class-openai-provider.php` - Responses API migration
- `providers/class-deepseek-provider.php` - Method visibility fixes

### Supporting Changes
- `includes/class-metabox.php` - Streaming UI setup
- `includes/class-schema-output.php` - Validation consistency
- `wp-ai-seo-schema-generator.php` - Version updates

## API Changes

### Request Format (OpenAI)
**Before (Chat Completions):**
```php
array(
    'model' => 'gpt-5-nano',
    'messages' => [...],
    'max_completion_tokens' => 128000,
    'reasoning_effort' => 'minimal',
    'stream' => true,
)
```

**After (Responses API):**
```php
array(
    'model' => 'gpt-5-nano',
    'input' => [...],
    'max_output_tokens' => 128000,
    'reasoning' => array('effort' => 'minimal'),
    'text' => array('verbosity' => 'low'),
    'stream' => true,
)
```

### Streaming Event Format
**Before (Chat Completions):**
```json
{
  "choices": [{
    "delta": {"content": "..."}
  }]
}
```

**After (Responses API):**
```json
{
  "type": "response.output_text.delta",
  "delta": "..."
}
```

## Performance Improvements

| Phase | Before | After | Improvement |
|-------|--------|-------|-------------|
| Pass 1 (Analysis) | 11s | 6-11s | âœ… Optimized |
| Pass 2 (Schema) | 190s | 10-20s | âš¡ **90% faster** |
| Total (2-pass) | ~200s | ~20-30s | ðŸš€ **85% faster** |

## Breaking Changes
None - fully backward compatible

## Version History

- **v1.7.0** - Initial streaming implementation
- **v1.7.1** - Responses API migration
- **v1.7.2** - Debug output to browser console
- **v1.7.3** - Fix default model bug (CRITICAL)
- **v1.7.4-v1.7.6** - Debug checkpoints for hang investigation
- **v1.7.7** - Fix fastcgi_finish_request bug (CRITICAL)
- **v1.7.8** - Fix method visibility (CRITICAL)
- **v1.7.9** - Validation consistency

## Testing Checklist

- [x] Pass 1 completes in 6-20 seconds
- [x] Pass 2 completes in 10-20 seconds (not 5 minutes)
- [x] Streaming progress shows in UI
- [x] Character counts update in real-time
- [x] Keepalive events prevent timeouts
- [x] Schema validates successfully
- [x] Both DeepSeek and OpenAI work
- [x] Diagnostics match Validate button

## Known Issues
None

## Future Improvements
- Consider using Responses API's `previous_response_id` for better caching
- Explore `extended_cache` for 90% token discount
- Add configurable reasoning effort levels
- Support for streaming in single-pass mode

## Credits
- OpenAI Responses API: https://platform.openai.com/docs/api-reference/responses
- SSE Implementation: Server-Sent Events standard
- Testing & Bug Discovery: User feedback and systematic debugging
